# Mock Task - Knowledge Base API

A FastAPI-based knowledge base management system that allows you to create knowledge bases, upload resources, and monitor their processing status. Features comprehensive testing tools, automated CI/CD, and deterministic resource processing.

## Features

- **Knowledge Base Management**: Create and manage knowledge bases
- **Resource Upload**: Upload files to knowledge bases with automatic token generation
- **Status Monitoring**: Track resource processing status (pending → parsed → indexed/error)
- **Deterministic Processing**: Predictable status evolution based on deterministic algorithms
- **Comprehensive Testing**: Automated smoke tests with fixture generation
- **Retries & Resilience**: Runner tolerates per-file upload failures and retries transient errors
- **Structured JSON Logs**: Consistent logging for both server and runner
- **Clean Client-Server Boundary**: Runner interacts with the API strictly over HTTP
- **CI/CD Pipeline**: GitHub Actions workflow for lint + smoke testing
- **Multiple File Formats**: Support for DOCX, PDF, PPTX, XLSX, TXT, MD, CSV, HTML, JSON, PNG

## Quick Start

### Prerequisites

- Python 3.11+ (CI uses 3.11)
- Virtual environment (recommended)

### Installation

1. Clone the repository
2. Create and activate virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Running the Server

```bash
source .venv/bin/activate
uvicorn app.main:app --reload --port 8000
```

The server will be available at `http://127.0.0.1:8000`

## API Usage

### 1. Create a Knowledge Base

```bash
KB=$(curl -s -X POST http://127.0.0.1:8000/knowledge_bases | python -c "import sys, json; print(json.load(sys.stdin)['knowledge_base_id'])")
echo "KB=$KB"
```

### 2. Generate Test Fixtures

```bash
python tools/fixtures.py
```

This creates 10 test files in the `fixtures/` directory for testing different file formats.

### 3. Upload a Resource

```bash
TOK=$(curl -s -X POST "http://127.0.0.1:8000/knowledge_bases/$KB/resources" \
  -F resource_type=file \
  -F resource_path=fixtures/Doc/Report.DOCX \
  -F file=@fixtures/doc/Report.DOCX | python -c "import sys, json; print(json.load(sys.stdin)['resource_id'])")
echo "TOK=$TOK"
```

### 4. Monitor Resource Status

```bash
curl "http://127.0.0.1:8000/knowledge_bases/$KB/resources/children?ids=$TOK"
```

## API Endpoints

- `POST /knowledge_bases` - Create a new knowledge base
- `POST /knowledge_bases/{kb_id}/resources` - Upload a resource
- `GET /knowledge_bases/{kb_id}/resources/children` - Monitor resource status
- `DELETE /knowledge_bases/{kb_id}` - Delete a knowledge base
- `GET /health` - Health check

## Project Structure

```
mock_task/
├── app/                    # Main application
│   ├── domain/            # Core business logic
│   │   ├── paths.py       # Path normalization
│   │   ├── tokens.py      # Token encoding/decoding
│   │   └── status.py      # Status computation
│   ├── api/               # API routes and models
│   │   ├── routes.py      # FastAPI routes
│   │   └── models.py      # Pydantic models
│   ├── service/           # Business services
│   │   └── kb_service.py  # Knowledge base service
│   ├── logging_conf.py    # Logging configuration
│   └── main.py            # FastAPI application
├── fixtures/              # Test files (generated by tools/fixtures.py)
│   ├── doc/Report.DOCX
│   ├── pdf/Spec.PDF
│   ├── ppt/Slides.PPTX
│   ├── xlsx/Data.XLSX
│   ├── txt/readme.txt
│   ├── md/notes.MD
│   ├── csv/table.CSV
│   ├── html/page.html
│   ├── json/config.json
│   └── img/pixel.png
├── runner/                 # Test runner (modular)
│   ├── cli.py             # CLI arg parsing
│   ├── client.py          # HTTP calls with retries and logging
│   ├── types.py           # Dataclasses and custom exceptions
│   ├── utils.py           # Small helpers (percentiles, summaries)
│   └── smoke.py           # Orchestrates the end-to-end flow
│   └── logging_conf.py    # Runner-only JSON logging (decoupled from server)
├── tools/                  # Utility scripts
│   └── fixtures.py         # Generate test fixtures
├── .github/workflows/      # CI/CD
│   └── ci.yml             # GitHub Actions workflow
├── requirements.txt        # Dependencies
├── test.py                # Basic test script
└── README.md              # This file
```

## Architecture & Boundaries

- The runner is a separate client that communicates with the FastAPI app only via HTTP (using `httpx`). It does not import any modules from `app.*`.
- The server encapsulates all business logic and normalization:
  - `resource_path` normalization occurs server-side in `app/service/kb_service.py` via `app/domain/paths.py`.
- Logging is implemented separately on both sides:
  - Server uses `app/logging_conf.py`.
  - Runner uses `runner/logging_conf.py`.

## Mermaid Diagram 

```mermaid
flowchart LR
  %% Layout: left-to-right for readability

  subgraph Client[Client]
    CLI[CLI / curl / runner]
  end

  %% API with internal layers nested
  subgraph API[FastAPI App]
    H[/GET /health/]
    R1[POST /knowledge_bases]
    R2[POST /knowledge_bases/:kb/resources]
    R3[GET /knowledge_bases/:kb/resources/children]
    R4[DELETE /knowledge_bases/:kb]

    subgraph Service[Service Layer]
      S1[kb_service.create_kb]
      S2[kb_service.upload_resource]
      S3[kb_service.list_children]
    end

    subgraph Domain[Domain Utilities]
      D1[paths.normalize_resource_path]
      D2[tokens.encode/decode_resource_token]
      D3[status.compute_status]
    end
  end

  %% Flows (always via API, never direct client→service/domain)
  CLI -->|HTTP JSON only| H

  CLI -->|HTTP JSON| R1
  R1 --> S1 --> R1
  R1 -->|JSON {knowledge_base_id}| CLI

  CLI -->|multipart/form-data| R2
  R2 --> S2 --> D1 --> D2 --> S2 --> R2
  R2 -->|JSON {resource_id, resource_path, status}| CLI

  CLI -->|HTTP JSON| R3
  R3 --> S3 --> D2 --> D3 --> S3 --> R3
  R3 -->|JSON {items: [...]}| CLI

  CLI -->|HTTP| R4
  R4 --> S1
```

Tip: Paste the Mermaid block into Mermaid Live (`https://mermaid.live`) or Excalidraw (`https://excalidraw.com`) to tweak spacing, colors, and export as SVG/PNG.

## Testing

### Basic Test

Run the basic test script to see the system in action:

```bash
python test.py
```

This will demonstrate:
- Path normalization
- Token encoding/decoding
- Status evolution simulation

### Comprehensive Smoke Test (resilient)

Run the full smoke test suite that uploads all fixture files and monitors their processing:

```bash
python -m runner.smoke --base-url http://127.0.0.1:8000
```

This comprehensive test:
- Creates a knowledge base
- Uploads 10 different file formats (continues even if some fail)
- Retries transient errors during create/upload/poll
- Monitors processing status
- Reports success/failure statistics and timing percentiles

### Expected Results

The smoke test typically shows:
- **8 files indexed** (successfully processed)
- **2 files failed** (CSV and PDF - deterministic failure simulation)
- **Average processing time**: ~1000ms
- **Deterministic behavior**: Same results every time with same seed

## Development

The server runs with auto-reload enabled, so changes to the code will automatically restart the server.

### Dependencies

The project uses:
- **FastAPI**: Web framework
- **Uvicorn**: ASGI server
- **Pydantic**: Data validation
- **httpx**: HTTP client for testing
- **python-multipart**: File upload support

### Environment Variables

- `CI_RUN_SEED`: Seed for deterministic behavior (default: 0)
- `FAILURE_RATE`: Rate of deterministic failures (default: 0.30)
- `LOG_LEVEL`: Server/runner log level (default: INFO)

## CI/CD

The project includes a GitHub Actions workflow (`.github/workflows/ci.yml`) that:

- Runs on every push and pull request
- Tests with Python 3.11
- Generates fixtures automatically
- Runs comprehensive smoke tests
- Uploads logs as artifacts for debugging
- Uses deterministic testing for consistent results

## License

This is a mock task project for demonstration purposes.
# Trigger CI
